{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7288dd7-a32a-4fa3-97d7-63db646410b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(287113, 13368, 11490, dict_keys(['article', 'highlights', 'id']))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) deps\n",
    "!pip -q install datasets\n",
    "\n",
    "# 2) load CNN/DailyMail **parquet** mirror\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Prefer the official Parquet-converted mirror (no scripts needed)\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")  # uses parquet\n",
    "train, val, test = ds[\"train\"], ds[\"validation\"], ds[\"test\"]\n",
    "len(train), len(val), len(test), test[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a110677a-54cd-48fa-85d7-9804bdd85198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 06:02:09.898823: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 06:02:35.940135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 06:02:49.120101: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint BLEURT-20-D12.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20-D12\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20-D12\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 06:03:01.599961: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-09-02 06:03:02.292646: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 61593600 exceeds 10% of free system memory.\n",
      "2025-09-02 06:03:04.519594: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 16777216 exceeds 10% of free system memory.\n",
      "2025-09-02 06:03:04.572333: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 16777216 exceeds 10% of free system memory.\n",
      "2025-09-02 06:03:04.676549: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 16777216 exceeds 10% of free system memory.\n",
      "2025-09-02 06:03:04.724908: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 16777216 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Average batch sequence length: 199.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Average batch sequence length: 199.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEURT: 0.2799194859713316 N: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cnndm_bleurt_lead3.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from bleurt import score\n",
    "\n",
    "def lead3(text):\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    out = \" \".join(sents[:3]) if sents else text.strip()\n",
    "    # keep short so BLEURT stays under 512 subword tokens\n",
    "    return out[:2000]\n",
    "\n",
    "N = 200  # subset for a quick run; set None for full split\n",
    "subset = test.select(range(N)) if N else test\n",
    "references = subset[\"highlights\"]   # gold reference summaries\n",
    "candidates = [lead3(a) for a in subset[\"article\"]]\n",
    "\n",
    "scorer = score.LengthBatchingBleurtScorer(\"BLEURT-20-D12\")  # or \"BLEURT-20\"\n",
    "scores = scorer.score(references=references, candidates=candidates, batch_size=64)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "out = pd.DataFrame({\"id\": subset[\"id\"], \"reference\": references, \"candidate\": candidates, \"bleurt\": scores})\n",
    "print(\"Mean BLEURT:\", float(np.mean(scores)), \"N:\", len(scores))\n",
    "out.to_csv(\"cnndm_bleurt_lead3.csv\", index=False)\n",
    "\"cnndm_bleurt_lead3.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02b5459-20f7-4c1c-aa4b-74f12c4b97e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: cnndm_refs.txt cnndm_cands_lead3_stream.txt\n"
     ]
    }
   ],
   "source": [
    "import re, pathlib\n",
    "from itertools import islice\n",
    "from datasets import load_dataset\n",
    "\n",
    "refs_path = pathlib.Path(\"cnndm_refs.txt\")\n",
    "cands_path = pathlib.Path(\"cnndm_cands_lead3_stream.txt\")\n",
    "\n",
    "SENT_SPLIT = re.compile(r'(?<=[.!?])\\s+')\n",
    "def lead3(t): \n",
    "    s = SENT_SPLIT.split(t.strip())\n",
    "    return (\" \".join(s[:3]) if s else t.strip()).replace(\"\\n\", \" \")[:2000]\n",
    "\n",
    "N = 200\n",
    "stream = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=\"test\", streaming=True)\n",
    "\n",
    "with refs_path.open(\"w\", encoding=\"utf-8\") as fr, cands_path.open(\"w\", encoding=\"utf-8\") as fc:\n",
    "    for ex in islice(stream, N):\n",
    "        fr.write(ex[\"highlights\"].replace(\"\\n\", \" \").strip() + \"\\n\")\n",
    "        fc.write(lead3(ex[\"article\"]) + \"\\n\")\n",
    "\n",
    "print(\"Wrote:\", refs_path, cands_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7b6957-ce95-4731-8f9f-8338b5cee50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote:\n",
      "  refs: /workspaces/bleurt/bleurt_runs/cnndm_lead3/refs.txt\n",
      "  cands: /workspaces/bleurt/bleurt_runs/cnndm_lead3/cands.txt\n",
      "Lines -> refs: 200 cands: 200\n"
     ]
    }
   ],
   "source": [
    "import os, re, pathlib\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Output folder (keeps things tidy)\n",
    "out_dir = pathlib.Path(\"bleurt_runs/cnndm_lead3\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "refs_path  = (out_dir / \"refs.txt\").resolve()\n",
    "cands_path = (out_dir / \"cands.txt\").resolve()\n",
    "\n",
    "# Light sentence splitter + lead-3 baseline\n",
    "SENT_SPLIT = re.compile(r'(?<=[.!?])\\s+')\n",
    "def lead3(text: str) -> str:\n",
    "    sents = SENT_SPLIT.split(text.strip())\n",
    "    out = \" \".join(sents[:3]) if sents else text.strip()\n",
    "    return out.replace(\"\\n\", \" \")[:2000]  # single line, <= ~512 subwords\n",
    "\n",
    "# Load only what you need server-side (low RAM)\n",
    "N = 200  # set to None for full test\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=f\"test[:{N}]\")\n",
    "\n",
    "# Write files line-by-line\n",
    "with refs_path.open(\"w\", encoding=\"utf-8\") as fr, cands_path.open(\"w\", encoding=\"utf-8\") as fc:\n",
    "    for ex in ds:\n",
    "        fr.write(ex[\"highlights\"].replace(\"\\n\", \" \").strip() + \"\\n\")\n",
    "        fc.write(lead3(ex[\"article\"]) + \"\\n\")\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"  refs:\", refs_path)\n",
    "print(\"  cands:\", cands_path)\n",
    "\n",
    "# Sanity check: files exist & have same number of lines\n",
    "def count_lines(p): \n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f: \n",
    "        return sum(1 for _ in f)\n",
    "n_refs, n_cands = count_lines(refs_path), count_lines(cands_path)\n",
    "print(\"Lines -> refs:\", n_refs, \"cands:\", n_cands)\n",
    "assert n_refs == n_cands and n_refs > 0, \"Ref/Cand line counts mismatch or empty!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b5d98c-b766-4b70-b805-2b11df1a4fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 06:12:52.373823: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 06:12:52.422157: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 06:12:54.505413: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 06:12:57.027547: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "INFO:tensorflow:Running BLEURT scoring.\n",
      "I0902 06:12:57.027747 138104150554432 score_files.py:168] Running BLEURT scoring.\n",
      "WARNING:tensorflow:Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "W0902 06:12:57.027957 138104150554432 score_files.py:118] Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "INFO:tensorflow:Reading checkpoint BLEURT-20-D12.\n",
      "I0902 06:12:57.028062 138104150554432 score.py:160] Reading checkpoint BLEURT-20-D12.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0902 06:12:57.028189 138104150554432 checkpoint.py:91] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20-D12\n",
      "I0902 06:12:57.028464 138104150554432 checkpoint.py:95] Will load checkpoint BLEURT-20-D12\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0902 06:12:57.028567 138104150554432 checkpoint.py:97] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20-D12\n",
      "I0902 06:12:57.028638 138104150554432 checkpoint.py:101] ... name:BLEURT-20-D12\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0902 06:12:57.028706 138104150554432 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "I0902 06:12:57.028803 138104150554432 checkpoint.py:101] ... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "I0902 06:12:57.028874 138104150554432 checkpoint.py:101] ... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "I0902 06:12:57.028942 138104150554432 checkpoint.py:101] ... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "I0902 06:12:57.029021 138104150554432 checkpoint.py:101] ... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "I0902 06:12:57.029110 138104150554432 checkpoint.py:101] ... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0902 06:12:57.029196 138104150554432 score.py:167] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 06:12:57.029271 138104150554432 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 06:12:57.029331 138104150554432 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "I0902 06:12:57.029396 138104150554432 tokenizers.py:60] Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "I0902 06:12:57.206615 138104150554432 tokenizers.py:64] SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0902 06:12:57.206844 138104150554432 score.py:56] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0902 06:12:57.206929 138104150554432 score.py:61] Loading model.\n",
      "2025-09-02 06:12:57.984024: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 61593600 exceeds 10% of free system memory.\n",
      "I0902 06:13:00.464197 138104150554432 load.py:1083] Fingerprint not found. Saved model loading will continue.\n",
      "I0902 06:13:00.464377 138104150554432 load.py:1102] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0902 06:13:00.466385 138104150554432 score.py:173] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0902 06:13:00.466514 138104150554432 score_files.py:132] Computing BLEURT scores...\n",
      "2025-09-02 06:13:00.811122: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 33292288 exceeds 10% of free system memory.\n",
      "2025-09-02 06:13:00.847513: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 33292288 exceeds 10% of free system memory.\n",
      "2025-09-02 06:13:00.847645: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 33292288 exceeds 10% of free system memory.\n",
      "2025-09-02 06:13:01.230867: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 33292288 exceeds 10% of free system memory.\n",
      "INFO:tensorflow:Average batch sequence length: 201.5\n",
      "I0902 06:15:51.306222 138104150554432 score.py:316] Average batch sequence length: 201.5\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0902 06:15:51.306483 138104150554432 score_files.py:140] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0902 06:15:51.306589 138104150554432 score_files.py:143] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0902 06:15:51.307362 138104150554432 score_files.py:150] Done.\n",
      "Scores saved to: /workspaces/bleurt/bleurt_runs/cnndm_lead3/scores.txt\n",
      "0.3035743832588196\n",
      "0.2520018219947815\n",
      "0.2647010087966919\n",
      "0.2512001395225525\n",
      "0.3313358426094055\n"
     ]
    }
   ],
   "source": [
    "scores_path = \"/workspaces/bleurt/bleurt_runs/cnndm_lead3/scores.txt\"\n",
    "ckpt = \"BLEURT-20-D12\"  # or \"BLEURT-20\" if you want the full model\n",
    "\n",
    "!python -m bleurt.score_files \\\n",
    "  -candidate_file=\"/workspaces/bleurt/bleurt_runs/cnndm_lead3/cands.txt\" \\\n",
    "  -reference_file=\"/workspaces/bleurt/bleurt_runs/cnndm_lead3/refs.txt\" \\\n",
    "  -bleurt_batch_size=64 \\\n",
    "  -batch_same_length=True \\\n",
    "  -bleurt_checkpoint=\"{ckpt}\" \\\n",
    "  -scores_file=\"{scores_path}\"\n",
    "\n",
    "print(\"Scores saved to:\", scores_path)\n",
    "!head -n 5 \"{scores_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798c6c3f-59cf-4bfb-9d94-0e46a892579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN/DailyMail Results:\n",
      "Mean BLEURT: 0.2791\n",
      "Standard Deviation: 0.0660\n",
      "N: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "cnn_path = Path(\"bleurt_runs/cnndm_lead3/scores.txt\")\n",
    "cnn_scores = np.loadtxt(cnn_path)\n",
    "print(\"CNN/DailyMail Results:\")\n",
    "print(f\"Mean BLEURT: {cnn_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation: {cnn_scores.std():.4f}\")\n",
    "print(f\"N: {len(cnn_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0859e-332c-41e4-b810-7211ae5f90e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
