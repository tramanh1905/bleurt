{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2943fe3e-fa05-4ba1-a4a6-d0207dc0c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43aea8cb-4c79-4fc4-87b0-24f28d38aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 2.21k/2.21k [00:00<00:00, 5.11kB/s]\n",
      "Downloading data: 100%|██████████| 228M/228M [00:09<00:00, 23.5MB/s] \n",
      "Downloading data: 100%|██████████| 229M/229M [00:09<00:00, 24.6MB/s] \n",
      "Downloading data: 100%|██████████| 26.1M/26.1M [00:01<00:00, 18.2MB/s]\n",
      "Downloading data: 100%|██████████| 24.0M/24.0M [00:01<00:00, 18.9MB/s]\n",
      "Generating train split: 100%|██████████| 17517/17517 [00:12<00:00, 1385.39 examples/s]\n",
      "Generating validation split: 100%|██████████| 973/973 [00:00<00:00, 3195.33 examples/s]\n",
      "Generating test split: 100%|██████████| 973/973 [00:01<00:00, 514.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: ccdv/govreport-summarization\n",
      "test size: 973 keys: dict_keys(['report', 'summary'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "CANDIDATE_DATASETS = [\n",
    "    \"ccdv/govreport-summarization\",  # common mirror\n",
    "    \"ccdv/govreport\",                # alt\n",
    "    \"ccdv/gov_report\",               # alt\n",
    "    \"GEM/govreport\",                 # alt (if available)\n",
    "]\n",
    "\n",
    "ds = None\n",
    "last_err = None\n",
    "for repo in CANDIDATE_DATASETS:\n",
    "    try:\n",
    "        ds = load_dataset(repo)\n",
    "        print(\"Loaded dataset:\", repo)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        continue\n",
    "if ds is None:\n",
    "    raise RuntimeError(f\"Could not load any GovReport mirror; last error:\\n{last_err}\")\n",
    "\n",
    "# Pick the split you want to evaluate on\n",
    "# Many mirrors provide 'train'/'validation'/'test'; if not, fall back to 'test' existence check.\n",
    "split_name = \"test\" if \"test\" in ds else \"validation\"\n",
    "data = ds[split_name]\n",
    "print(split_name, \"size:\", len(data), \"keys:\", data[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a43e69-233b-4b85-bf75-8e1dfe81cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns -> document: report reference: summary\n"
     ]
    }
   ],
   "source": [
    "example_keys = list(data[0].keys())\n",
    "doc_key = \"document\" if \"document\" in example_keys else (\"report\" if \"report\" in example_keys else \"article\")\n",
    "ref_key = \"summary\"  if \"summary\"  in example_keys else (\"reference\" if \"reference\" in example_keys else \"highlights\")\n",
    "print(\"Using columns -> document:\", doc_key, \"reference:\", ref_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa4d047-b5bd-4164-93b4-4070c2193c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote:\n",
      "  refs -> /workspaces/bleurt/bleurt_runs/govreport_lead7/refs.txt\n",
      "  cands -> /workspaces/bleurt/bleurt_runs/govreport_lead7/cands.txt\n",
      "Lines -> refs: 200 cands: 200\n"
     ]
    }
   ],
   "source": [
    "import re, pathlib\n",
    "\n",
    "# Output paths (absolute to avoid 'file not found')\n",
    "out_dir = pathlib.Path(\"bleurt_runs/govreport_lead7\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "refs_path  = (out_dir / \"refs.txt\").resolve()\n",
    "cands_path = (out_dir / \"cands.txt\").resolve()\n",
    "\n",
    "SENT_SPLIT = re.compile(r'(?<=[.!?])\\s+')\n",
    "\n",
    "def lead_k(text: str, k: int = 7, char_cap: int = 3000) -> str:\n",
    "    sents = SENT_SPLIT.split(text.strip())\n",
    "    out = \" \".join(sents[:k]) if sents else text.strip()\n",
    "    # ensure single line + modest length\n",
    "    return out.replace(\"\\n\", \" \")[:char_cap]\n",
    "\n",
    "# Evaluate a manageable subset first; set N=None for the full split once you’re happy\n",
    "N = 200\n",
    "subset = data.select(range(N)) if N else data\n",
    "\n",
    "with refs_path.open(\"w\", encoding=\"utf-8\") as fr, cands_path.open(\"w\", encoding=\"utf-8\") as fc:\n",
    "    for ex in subset:\n",
    "        ref = str(ex[ref_key]).replace(\"\\n\", \" \").strip()\n",
    "        cand = lead_k(str(ex[doc_key]))\n",
    "        fr.write(ref + \"\\n\")\n",
    "        fc.write(cand + \"\\n\")\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"  refs ->\", refs_path)\n",
    "print(\"  cands ->\", cands_path)\n",
    "\n",
    "# Quick sanity check: equal counts\n",
    "def count_lines(p):\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        return sum(1 for _ in f)\n",
    "n_refs, n_cands = count_lines(refs_path), count_lines(cands_path)\n",
    "print(\"Lines -> refs:\", n_refs, \"cands:\", n_cands)\n",
    "assert n_refs == n_cands and n_refs > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32913c9f-69f1-401a-954a-4e7d0e27e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 12:37:39.933566: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 12:38:02.639734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 12:38:14.253754: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 12:38:26.167542: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "INFO:tensorflow:Running BLEURT scoring.\n",
      "I0902 12:38:26.167668 128407618672448 score_files.py:168] Running BLEURT scoring.\n",
      "WARNING:tensorflow:Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "W0902 12:38:26.167879 128407618672448 score_files.py:118] Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "INFO:tensorflow:Reading checkpoint BLEURT-20-D12.\n",
      "I0902 12:38:26.167981 128407618672448 score.py:160] Reading checkpoint BLEURT-20-D12.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0902 12:38:26.168128 128407618672448 checkpoint.py:91] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20-D12\n",
      "I0902 12:38:26.168679 128407618672448 checkpoint.py:95] Will load checkpoint BLEURT-20-D12\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0902 12:38:26.168767 128407618672448 checkpoint.py:97] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20-D12\n",
      "I0902 12:38:26.168835 128407618672448 checkpoint.py:101] ... name:BLEURT-20-D12\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0902 12:38:26.168900 128407618672448 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "I0902 12:38:26.169012 128407618672448 checkpoint.py:101] ... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "I0902 12:38:26.169085 128407618672448 checkpoint.py:101] ... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "I0902 12:38:26.169147 128407618672448 checkpoint.py:101] ... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "I0902 12:38:26.169242 128407618672448 checkpoint.py:101] ... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "I0902 12:38:26.169353 128407618672448 checkpoint.py:101] ... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0902 12:38:26.169430 128407618672448 score.py:167] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 12:38:26.169501 128407618672448 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 12:38:26.169561 128407618672448 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "I0902 12:38:26.169620 128407618672448 tokenizers.py:60] Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "I0902 12:38:26.641618 128407618672448 tokenizers.py:64] SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0902 12:38:26.641809 128407618672448 score.py:56] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0902 12:38:26.641887 128407618672448 score.py:61] Loading model.\n",
      "2025-09-02 12:38:27.665463: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 61593600 exceeds 10% of free system memory.\n",
      "I0902 12:39:19.716172 128407618672448 load.py:1083] Fingerprint not found. Saved model loading will continue.\n",
      "I0902 12:39:19.716351 128407618672448 load.py:1102] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0902 12:39:19.718280 128407618672448 score.py:173] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0902 12:39:19.718386 128407618672448 score_files.py:132] Computing BLEURT scores...\n",
      "2025-09-02 12:39:20.371643: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 33554432 exceeds 10% of free system memory.\n",
      "2025-09-02 12:39:20.978791: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2025-09-02 12:39:21.050970: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2025-09-02 12:39:21.051029: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "INFO:tensorflow:Average batch sequence length: 512.0\n",
      "I0902 12:48:40.453107 128407618672448 score.py:316] Average batch sequence length: 512.0\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0902 12:48:40.453438 128407618672448 score_files.py:140] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0902 12:48:40.453551 128407618672448 score_files.py:143] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0902 12:48:40.454332 128407618672448 score_files.py:150] Done.\n",
      "0.3791719079017639\n",
      "0.3545835018157959\n",
      "0.34173500537872314\n",
      "0.35277485847473145\n",
      "0.3230743408203125\n",
      "Scores saved to: /workspaces/bleurt/bleurt_runs/govreport_lead7/scores.txt\n"
     ]
    }
   ],
   "source": [
    "scores_path = (out_dir / \"scores.txt\").resolve()\n",
    "ckpt = \"BLEURT-20-D12\"  # or \"BLEURT-20\" for the full model\n",
    "\n",
    "!python -m bleurt.score_files \\\n",
    "  -candidate_file=\"{cands_path}\" \\\n",
    "  -reference_file=\"{refs_path}\" \\\n",
    "  -bleurt_batch_size=32 \\\n",
    "  -batch_same_length=True \\\n",
    "  -bleurt_checkpoint=\"{ckpt}\" \\\n",
    "  -scores_file=\"{scores_path}\"\n",
    "\n",
    "!head -n 5 \"{scores_path}\"\n",
    "print(\"Scores saved to:\", scores_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2d4e6d-e8d4-4e88-94c1-2aded4358a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEURT: 0.3434018988907337 N: 200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = np.loadtxt(scores_path)\n",
    "print(\"Mean BLEURT:\", float(scores.mean()), \"N:\", scores.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c34e78-4091-4da2-ba64-307a2e12d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GovReport Results:\n",
      "Mean BLEURT: 0.3434\n",
      "Standard Deviation: 0.0292\n",
      "N: 200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "gov_path = Path(\"bleurt_runs/govreport_lead7/scores.txt\")\n",
    "gov_scores = np.loadtxt(gov_path)\n",
    "print(\"GovReport Results:\")\n",
    "print(f\"Mean BLEURT: {gov_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation: {gov_scores.std():.4f}\")\n",
    "print(f\"N: {len(gov_scores)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8db12-ddbf-41e6-97ed-f4c7c1f0d223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
