{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac9652f-7cea-4907-a7a0-af2db491a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.21.0)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyarrow in /usr/local/python/3.12.1/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (2024.6.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.12.15)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /home/codespace/.local/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, fsspec, ipywidgets, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2024.6.1\n",
      "\u001b[2K    Uninstalling fsspec-2024.6.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2024.6.1\n",
      "\u001b[2K  Attempting uninstall: datasets\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [ipywidgets]\n",
      "\u001b[2K    Found existing installation: datasets 2.21.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [ipywidgets]\n",
      "\u001b[2K    Uninstalling datasets-2.21.0:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [ipywidgets]\n",
      "\u001b[2K      Successfully uninstalled datasets-2.21.0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [ipywidgets]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [datasets]\u001b[33m  WARNING: The script datasets-cli is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  NOTE: The current PATH contains path(s) starting with `~`, which may not be expanded by all applications.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-4.0.0 fsspec-2025.3.0 ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U datasets pyarrow fsspec aiohttp ipywidgets\n",
    "# If the kernel just updated packages, you may need to restart the kernel once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea14ad4-d943-4941-b03e-f0e6e0ef6bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcc0b8f49d34f71958e553370ae8282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db0444a95774b0d86536bc8c718224f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b9b04088b5445ca546e177a71963bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/171k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ec671a2772440ba415abefb2dfd735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/31.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d9378c6aa64a6fa41177561a405b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67389 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125c8f3db07c4bbb8b58fefe2db72e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111965233f8a4d1bb0043ef3e9295033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: allenai/common_gen\n",
      "Split: validation size: 4018 keys: ['concept_set_idx', 'concepts', 'target']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mirrors = [\"allenai/common_gen\", \"GEM/common_gen\"]\n",
    "ds, last_err = None, None\n",
    "for repo in mirrors:\n",
    "    try:\n",
    "        ds = load_dataset(repo)\n",
    "        print(\"Loaded:\", repo)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "if ds is None:\n",
    "    raise RuntimeError(f\"Could not load CommonGen. Last error:\\n{last_err}\")\n",
    "\n",
    "split = \"validation\" if \"validation\" in ds else \"test\"\n",
    "data = ds[split]\n",
    "print(\"Split:\", split, \"size:\", len(data), \"keys:\", list(data[0].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db25f04f-cf6f-43c3-a7dd-21a0a635f550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['field', 'look', 'stand'],\n",
       " ['The player stood in the field looking at the batter.'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_fields(ex):\n",
    "    # concepts may be under 'concepts' or 'concept_set'\n",
    "    concepts = ex.get(\"concepts\") or ex.get(\"concept_set\")\n",
    "    if isinstance(concepts, str):  # rare case: comma/space-separated string\n",
    "        concepts = [c.strip() for c in concepts.replace(\",\", \" \").split()]\n",
    "    assert isinstance(concepts, (list, tuple)) and len(concepts) > 0, \"No concepts found\"\n",
    "    concepts = [str(c) for c in concepts]\n",
    "\n",
    "    # references usually 'references' (list[str]) or 'target' (str)\n",
    "    if \"references\" in ex and isinstance(ex[\"references\"], (list, tuple)):\n",
    "        refs = [str(r) for r in ex[\"references\"]]\n",
    "    elif \"target\" in ex:\n",
    "        refs = [str(ex[\"target\"])]\n",
    "    else:\n",
    "        raise KeyError(f\"No reference text in example keys: {list(ex.keys())}\")\n",
    "    return concepts, refs\n",
    "\n",
    "# quick peek\n",
    "c0, r0 = extract_fields(data[0])\n",
    "c0, r0[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d07a6f-03b8-4539-bcbb-ee6bca1559ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4018,\n",
       " 4018,\n",
       " 'field, look, and stand appear together in a scene.',\n",
       " ['The player stood in the field looking at the batter.'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concepts_to_sentence(concepts):\n",
    "    # keep order; join into a simple one-sentence description\n",
    "    # e.g., [\"dog\",\"park\",\"run\",\"child\"] -> \"A dog and a child run in a park.\"\n",
    "    words = [w.replace(\"_\", \" \") for w in concepts]\n",
    "    if len(words) == 1:\n",
    "        sent = f\"{words[0]}.\"\n",
    "    elif len(words) == 2:\n",
    "        sent = f\"{words[0]} and {words[1]}.\"\n",
    "    else:\n",
    "        sent = \", \".join(words[:-1]) + f\", and {words[-1]}.\"\n",
    "    # add a light template for plausibility\n",
    "    sent = f\"{sent[:-1]} appear together in a scene.\"\n",
    "    return sent[:300]  # keep short for BLEURT\n",
    "\n",
    "cands = []\n",
    "refs_list = []\n",
    "for ex in data:\n",
    "    concepts, refs = extract_fields(ex)\n",
    "    cands.append(concepts_to_sentence(concepts))\n",
    "    refs_list.append(refs)\n",
    "len(cands), len(refs_list), cands[0], refs_list[0][:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65327bcf-639e-4825-ab96-26415edf455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote:\n",
      "  refs  -> /workspaces/bleurt/bleurt_runs/commongen_rule/refs.txt\n",
      "  cands -> /workspaces/bleurt/bleurt_runs/commongen_rule/cands.txt\n",
      "  map   -> /workspaces/bleurt/bleurt_runs/commongen_rule/example_index.txt\n",
      "Total expanded pairs: 1000\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "out_dir = pathlib.Path(\"bleurt_runs/commongen_rule\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "refs_path   = (out_dir / \"refs.txt\").resolve()\n",
    "cands_path  = (out_dir / \"cands.txt\").resolve()\n",
    "index_path  = (out_dir / \"example_index.txt\").resolve()\n",
    "\n",
    "N = 1000  # start small; set to None for full split\n",
    "indices = range(len(cands)) if N is None else range(min(N, len(cands)))\n",
    "\n",
    "num_pairs = 0\n",
    "with refs_path.open(\"w\", encoding=\"utf-8\") as fr, \\\n",
    "     cands_path.open(\"w\", encoding=\"utf-8\") as fc, \\\n",
    "     index_path.open(\"w\", encoding=\"utf-8\") as fi:\n",
    "    for i in indices:\n",
    "        cand = cands[i].replace(\"\\n\", \" \")\n",
    "        for ref in refs_list[i]:\n",
    "            fr.write(ref.replace(\"\\n\", \" \").strip() + \"\\n\")\n",
    "            fc.write(cand + \"\\n\")\n",
    "            fi.write(str(i) + \"\\n\")\n",
    "            num_pairs += 1\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"  refs  ->\", refs_path)\n",
    "print(\"  cands ->\", cands_path)\n",
    "print(\"  map   ->\", index_path)\n",
    "print(\"Total expanded pairs:\", num_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2888a6-8fc0-4035-b4d5-6349224e4e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 13:14:22.185225: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 13:14:44.990290: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 13:14:55.906521: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 13:15:08.094282: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "INFO:tensorflow:Running BLEURT scoring.\n",
      "I0902 13:15:08.094561 133888825157440 score_files.py:168] Running BLEURT scoring.\n",
      "WARNING:tensorflow:Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "W0902 13:15:08.094854 133888825157440 score_files.py:118] Enabling same length batching. BEWARE: this is an experimental feature.\n",
      "INFO:tensorflow:Reading checkpoint BLEURT-20-D12.\n",
      "I0902 13:15:08.094980 133888825157440 score.py:160] Reading checkpoint BLEURT-20-D12.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0902 13:15:08.095142 133888825157440 checkpoint.py:91] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20-D12\n",
      "I0902 13:15:08.095687 133888825157440 checkpoint.py:95] Will load checkpoint BLEURT-20-D12\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0902 13:15:08.095777 133888825157440 checkpoint.py:97] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20-D12\n",
      "I0902 13:15:08.095854 133888825157440 checkpoint.py:101] ... name:BLEURT-20-D12\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0902 13:15:08.095921 133888825157440 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "I0902 13:15:08.096031 133888825157440 checkpoint.py:101] ... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "I0902 13:15:08.096106 133888825157440 checkpoint.py:101] ... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "I0902 13:15:08.096170 133888825157440 checkpoint.py:101] ... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "I0902 13:15:08.096270 133888825157440 checkpoint.py:101] ... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "I0902 13:15:08.096386 133888825157440 checkpoint.py:101] ... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0902 13:15:08.096465 133888825157440 score.py:167] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 13:15:08.096540 133888825157440 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "I0902 13:15:08.096604 133888825157440 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "I0902 13:15:08.096669 133888825157440 tokenizers.py:60] Will load model: BLEURT-20-D12/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "I0902 13:15:08.557073 133888825157440 tokenizers.py:64] SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0902 13:15:08.557288 133888825157440 score.py:56] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0902 13:15:08.557369 133888825157440 score.py:61] Loading model.\n",
      "2025-09-02 13:15:09.610501: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 61593600 exceeds 10% of free system memory.\n",
      "I0902 13:16:01.529115 133888825157440 load.py:1083] Fingerprint not found. Saved model loading will continue.\n",
      "I0902 13:16:01.529315 133888825157440 load.py:1102] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0902 13:16:01.531436 133888825157440 score.py:173] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0902 13:16:01.531552 133888825157440 score_files.py:132] Computing BLEURT scores...\n",
      "2025-09-02 13:16:03.627949: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "2025-09-02 13:16:04.054738: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "2025-09-02 13:16:04.054858: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "2025-09-02 13:16:04.662799: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 42598400 exceeds 10% of free system memory.\n",
      "INFO:tensorflow:Average batch sequence length: 32.1\n",
      "I0902 13:18:28.631903 133888825157440 score.py:316] Average batch sequence length: 32.1\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0902 13:18:28.632507 133888825157440 score_files.py:140] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0902 13:18:28.632611 133888825157440 score_files.py:143] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0902 13:18:28.635090 133888825157440 score_files.py:150] Done.\n",
      "0.33766913414001465\n",
      "0.30702072381973267\n",
      "0.35506123304367065\n",
      "0.3513478636741638\n",
      "0.3456963896751404\n"
     ]
    }
   ],
   "source": [
    "scores_path = (out_dir / \"scores.txt\").resolve()\n",
    "ckpt = \"BLEURT-20-D12\"  # distilled, fast on CPU\n",
    "\n",
    "!python -m bleurt.score_files \\\n",
    "  -candidate_file=\"{cands_path}\" \\\n",
    "  -reference_file=\"{refs_path}\" \\\n",
    "  -bleurt_batch_size=100 \\\n",
    "  -batch_same_length=True \\\n",
    "  -bleurt_checkpoint=\"{ckpt}\" \\\n",
    "  -scores_file=\"{scores_path}\"\n",
    "\n",
    "!head -n 5 \"{scores_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e27f0d1-7db4-4e7b-b0b1-f73ac3382fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples scored: 1000\n",
      "Mean BLEURT (avg over refs per example): 0.34721828971803187\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "scores = np.loadtxt(scores_path)\n",
    "with open(index_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    idx_map = [int(x.strip()) for x in f]\n",
    "assert len(scores) == len(idx_map)\n",
    "\n",
    "buckets = defaultdict(list)\n",
    "for s, i in zip(scores, idx_map):\n",
    "    buckets[i].append(float(s))\n",
    "\n",
    "per_example = np.array([np.mean(buckets[i]) for i in sorted(buckets.keys())])\n",
    "print(\"Examples scored:\", per_example.size)\n",
    "print(\"Mean BLEURT (avg over refs per example):\", float(per_example.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a738cfe-15b9-48a0-bdc3-d9cbd357ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommonGen Results:\n",
      "Mean BLEURT: 0.3472\n",
      "Standard Deviation: 0.0471\n",
      "N: 1000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "common_path = Path(\"bleurt_runs/commongen_rule/scores.txt\")\n",
    "common_scores = np.loadtxt(common_path)\n",
    "\n",
    "print(\"CommonGen Results:\")\n",
    "print(f\"Mean BLEURT: {common_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation: {common_scores.std():.4f}\")\n",
    "print(f\"N: {len(common_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2776bf52-cda9-4fc2-9f24-3eb95c1e4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommonGen BLEURT: 1000 examples (mean=0.3472, std=0.0471)\n",
      "\n",
      "⚠️ No human ratings found. To compute BLEURT↔human correlations (as in the BLEURT paper), provide one of the following:\n",
      "  • CSV: commongen_human_ratings.csv with columns [example_id, human_score]\n",
      "  • TXT: commongen_human_ratings.txt with one score per *example* in the order of sorted example ids\n",
      "Examples expected: 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "\n",
    "# === 1) Required BLEURT inputs (from your CommonGen scoring) ===\n",
    "base = Path(\"bleurt_runs/commongen_rule\")\n",
    "scores_path = base / \"scores.txt\"\n",
    "index_path  = base / \"example_index.txt\"\n",
    "assert scores_path.exists(), f\"Missing BLEURT scores: {scores_path}\"\n",
    "assert index_path.exists(),  f\"Missing example index: {index_path}\"\n",
    "\n",
    "# Load BLEURT scores and map to example ids, then average over refs per example\n",
    "scores = np.loadtxt(scores_path, dtype=float, ndmin=1)\n",
    "with index_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    idx_map = [int(x.strip()) for x in f]\n",
    "assert len(scores) == len(idx_map), f\"Length mismatch: {len(scores)} scores vs {len(idx_map)} indices\"\n",
    "\n",
    "buckets = defaultdict(list)\n",
    "for s, i in zip(scores, idx_map):\n",
    "    buckets[i].append(float(s))\n",
    "bleurt_per_example = np.array([np.mean(buckets[i]) for i in sorted(buckets.keys())], dtype=float)\n",
    "example_ids = np.array(sorted(buckets.keys()), dtype=int)\n",
    "\n",
    "print(f\"CommonGen BLEURT: {len(bleurt_per_example)} examples \"\n",
    "      f\"(mean={bleurt_per_example.mean():.4f}, std={bleurt_per_example.std(ddof=0):.4f})\")\n",
    "\n",
    "# === 2) Human ratings (match the BLEURT article's correlation setup) ===\n",
    "# Provide one of these files:\n",
    "#   A) CSV with columns: [example_id,<one of: human_score, rating, DA>]\n",
    "#   B) TXT with a single score per line, same order as *unique* example ids (sorted) — last resort.\n",
    "rating_candidates = [\n",
    "    Path(\"commongen_human_ratings.csv\"),\n",
    "    Path(\"human_scores_commongen.csv\"),\n",
    "    base / \"human_scores.csv\",\n",
    "]\n",
    "\n",
    "ratings_df = None\n",
    "for p in rating_candidates:\n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p)\n",
    "        # id column\n",
    "        id_col = next((c for c in [\"example_id\",\"idx\",\"id\"] if c in df.columns), None)\n",
    "        # score column\n",
    "        sc_col = next((c for c in [\"human_score\",\"rating\",\"DA\",\"score\"] if c in df.columns), None)\n",
    "        if sc_col is not None:\n",
    "            if id_col is None:\n",
    "                # still usable if length matches and is clearly per-example\n",
    "                if len(df) == len(bleurt_per_example):\n",
    "                    ratings_df = pd.DataFrame({\n",
    "                        \"example_id\": example_ids,\n",
    "                        \"human_score\": pd.to_numeric(df[sc_col], errors=\"coerce\")\n",
    "                    })\n",
    "                    print(f\"Loaded ratings from {p} (no id column; aligned by sorted example ids).\")\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                ratings_df = df[[id_col, sc_col]].rename(columns={id_col:\"example_id\", sc_col:\"human_score\"})\n",
    "                ratings_df[\"example_id\"] = pd.to_numeric(ratings_df[\"example_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "                ratings_df[\"human_score\"] = pd.to_numeric(ratings_df[\"human_score\"], errors=\"coerce\")\n",
    "                print(f\"Loaded ratings from {p} with id column.\")\n",
    "            break\n",
    "\n",
    "if ratings_df is None:\n",
    "    # Fallback: plain text one score per line (aligned to sorted example_ids)\n",
    "    txt_fallbacks = [Path(\"commongen_human_ratings.txt\"), base / \"human_scores.txt\"]\n",
    "    txt_file = next((p for p in txt_fallbacks if p.exists()), None)\n",
    "    if txt_file is not None:\n",
    "        arr = np.loadtxt(txt_file, dtype=float, ndmin=1)\n",
    "        if arr.size == bleurt_per_example.size:\n",
    "            ratings_df = pd.DataFrame({\"example_id\": example_ids, \"human_score\": arr})\n",
    "            print(f\"Loaded ratings from {txt_file} (aligned by sorted example ids).\")\n",
    "\n",
    "# If still missing, stop with clear instructions\n",
    "if ratings_df is None:\n",
    "    print(\"\\n⚠️ No human ratings found. To compute BLEURT↔human correlations (as in the BLEURT paper), \"\n",
    "          \"provide one of the following:\\n\"\n",
    "          \"  • CSV: commongen_human_ratings.csv with columns [example_id, human_score]\\n\"\n",
    "          \"  • TXT: commongen_human_ratings.txt with one score per *example* in the order of sorted example ids\\n\"\n",
    "          f\"Examples expected: {len(bleurt_per_example)}\\n\")\n",
    "else:\n",
    "    # Align and drop NaNs\n",
    "    merged = (pd.DataFrame({\"example_id\": example_ids, \"bleurt\": bleurt_per_example})\n",
    "                .merge(ratings_df, on=\"example_id\", how=\"inner\")\n",
    "                .dropna(subset=[\"bleurt\",\"human_score\"]))\n",
    "\n",
    "    if merged.empty:\n",
    "        raise ValueError(\"Ratings present but no overlap with example ids. Check 'example_id' mapping.\")\n",
    "    x = merged[\"bleurt\"].to_numpy()\n",
    "    y = merged[\"human_score\"].to_numpy()\n",
    "\n",
    "    # === 3) Correlations (paper-style): Pearson r + Kendall τ (they report both) ===\n",
    "    # WMT17 used Pearson as official; WMT18–19 used a Kendall-based DARR variant. We'll report:\n",
    "    #   Pearson r, Spearman ρ, Kendall τ-b (all fast, robust).  :contentReference[oaicite:2]{index=2}\n",
    "    pr, pp = stats.pearsonr(x, y)\n",
    "    sr, sp = stats.spearmanr(x, y)\n",
    "    kt, kp = stats.kendalltau(x, y, variant=\"b\")\n",
    "\n",
    "    print(\"\\nCommonGen BLEURT ↔ Human Ratings:\")\n",
    "    print(f\"  N                : {len(x)}\")\n",
    "    print(f\"  Pearson r        : {pr:.4f} (p={pp:.2e})\")\n",
    "    print(f\"  Spearman ρ       : {sr:.4f} (p={sp:.2e})\")\n",
    "    print(f\"  Kendall τ-b      : {kt:.4f} (p={kp:.2e})\")\n",
    "\n",
    "    # === 4) Tiny bootstrap CIs (kept small for speed & stability) ===\n",
    "    rng = np.random.default_rng(123)\n",
    "    B = min(1000, max(300, len(x)*5))\n",
    "    idxs = rng.integers(0, len(x), size=(B, len(x)))\n",
    "    boots_p = np.array([stats.pearsonr(x[i], y[i])[0] for i in idxs])\n",
    "    lo, hi = np.quantile(boots_p, [0.025, 0.975])\n",
    "    print(f\"  95% CI (bootstrap, Pearson): [{lo:.4f}, {hi:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32cd13c-ab10-4b7b-b468-08f53b72efb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
